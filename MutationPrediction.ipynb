{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742621f2-2dcd-4416-9d51-4e26d379915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB import PDBParser, DSSP\n",
    "import sklearn as sl\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48590ca3-7275-459d-b674-86c80153a2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5365, 39900)\n",
      "(5365, 700, 57)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('cullpdb+profile_5926_filtered.npy.gz', allow_pickle=False)\n",
    "print(data.shape)\n",
    "reshaped = data.reshape(np.shape(data)[0], 700, 57)\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d0bd7-8b21-48f5-8ea2-116f34e7afa3",
   "metadata": {},
   "source": [
    "### Get primary structures and secondary structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196a84f7-747f-4a06-8d1a-a5a35e708d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "148\n",
      "['R', 'P', 'E', 'S', 'E', 'L', 'I', 'R', 'Q', 'S', 'W', 'R', 'V', 'V', 'S', 'R', 'S', 'P', 'L', 'E', 'H', 'G', 'T', 'V', 'L', 'F', 'A', 'R', 'L', 'F', 'A', 'L', 'E', 'P', 'S', 'L', 'L', 'P', 'L', 'F', 'Q', 'Y', 'N', 'G', 'R', 'Q', 'F', 'S', 'S', 'P', 'E', 'D', 'S', 'L', 'S', 'S', 'P', 'E', 'F', 'L', 'D', 'H', 'I', 'R', 'K', 'V', 'M', 'L', 'V', 'I', 'D', 'A', 'A', 'V', 'T', 'N', 'V', 'E', 'D', 'L', 'S', 'S', 'L', 'E', 'E', 'Y', 'L', 'T', 'S', 'L', 'G', 'R', 'K', 'H', 'R', 'A', 'V', 'G', 'V', 'R', 'L', 'S', 'S', 'F', 'S', 'T', 'V', 'G', 'E', 'S', 'L', 'L', 'Y', 'M', 'L', 'E', 'K', 'S', 'L', 'G', 'P', 'D', 'F', 'T', 'P', 'A', 'T', 'R', 'T', 'A', 'W', 'S', 'R', 'L', 'Y', 'G', 'A', 'V', 'V', 'Q', 'A', 'M', 'S', 'R', 'G', 'W', 'D', 'G']\n",
      "['C' 'C' 'C' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'C' 'C' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'C' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'C' 'C' 'E' 'C' 'C' 'E' 'C' 'C' 'C' 'C' 'H' 'H' 'H' 'H' 'C'\n",
      " 'C' 'C' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'C' 'C' 'C' 'C' 'C' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'C' 'C' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'C' 'C']\n",
      "Total proteins converted in single residues: 5365\n"
     ]
    }
   ],
   "source": [
    "all_residues = ['A','C','E','D','G','F','I','H','K','M','L','N','Q','P','S','R','T','W','V','Y','X','NoSeq']\n",
    "desired_sequence = 'MEPKVAELKQKIEDTLCPFGFEVYPFQVAWYNELLPPAFHLPLPGPTLAFLVLSTPAMFDRALKPFLQSCHLRMLTDPVDQCVAYHLGRVRESLPELQIEIIADYEVHPNRRPKILAQTAAHVAGAAYYYQRQDVEADPWGNQRISGVCIHPRFGGWFAIRGVVLLPGIEVPDLPPRKPHDCVPTRADRIALLEGFNFHWRDWTYRDAVTPQERYSEEQKAYFSTPPAQRLALLGLAQPSEKPSSPSPDLPFTTPAPKKPGNPSRARSWLSPRVSPPASPGP'\n",
    "target_sequence = list(desired_sequence)\n",
    "all_structures = ['L', 'B', 'E', 'G', 'I', 'H', 'S', 'T', 'NoSeqS']\n",
    "structures_classes = ['H','E','C']\n",
    "dssp8_to_q3 = {\n",
    "    5: 0,  # H\n",
    "    3: 0,  # G\n",
    "    4: 0,  # I\n",
    "    2: 1,  # E\n",
    "    1: 1,  # B\n",
    "    0: 2,  # L\n",
    "    6: 2,  # S\n",
    "    7: 2   # T\n",
    "}\n",
    "str8_to_3 = {\n",
    "    'H':'H',\n",
    "    'G':'H',\n",
    "    'I':'H',\n",
    "    'E':'E',\n",
    "    'B':'E',\n",
    "    'L':'C',\n",
    "    'S':'C',\n",
    "    'T':'C'\n",
    "}\n",
    "\n",
    "# creating the list of sequences\n",
    "sequences = []\n",
    "structures = []\n",
    "for i in range(int(np.shape(reshaped)[0])):\n",
    "    prot = reshaped[i,:,:]\n",
    "\n",
    "    indices = np.argmax(prot[:,:22], axis = 1)\n",
    "    indices = indices[np.where(indices != 21)]\n",
    "    indices = [all_residues[index] for index in indices]\n",
    "    sequences.append(indices)\n",
    "\n",
    "    sec_indices = np.argmax(prot[:,22:31], axis = 1)\n",
    "    sec_indices = sec_indices[np.where(sec_indices != 8)]\n",
    "    sec_indices = [all_structures[index] for index in sec_indices]\n",
    "    # map into 3 classes\n",
    "    sec_indices = np.vectorize(str8_to_3.get)(sec_indices)\n",
    "    structures.append(sec_indices)\n",
    "    \n",
    "\n",
    "print(len(sequences[1]))\n",
    "print(len(structures[1]))\n",
    "print(sequences[1])\n",
    "print(structures[1])\n",
    "print(\"Total proteins converted in single residues:\",len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef52552-2859-4dee-bcfc-9a872898662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5365, 696])\n",
      "torch.Size([5365, 696])\n"
     ]
    }
   ],
   "source": [
    "# remamp into numbers\n",
    "aa_to_idx = {\n",
    "    'A': 0, 'C': 1, 'D': 2, 'E': 3,\n",
    "    'F': 4, 'G': 5, 'H': 6, 'I': 7,\n",
    "    'K': 8, 'L': 9, 'M': 10, 'N': 11,\n",
    "    'P': 12, 'Q': 13, 'R': 14, 'S': 15,\n",
    "    'T': 16, 'V': 17, 'W': 18, 'Y': 19, 'X': 20\n",
    "}\n",
    "dssp_to_idx = {\n",
    "    'H': 0,\n",
    "    'E': 1,\n",
    "    'C': 2\n",
    "}\n",
    "\n",
    "# GET PRIMARY STRUCTURES into TORCH\n",
    "aa_pad_idx = 21  # index for padding\n",
    "# Convert each sequence to tensor of indices\n",
    "seq_tensors = [torch.tensor([aa_to_idx.get(aa, aa_pad_idx) for aa in seq]) for seq in sequences]\n",
    "# Pad them to max length with padding value aa_pad_idx\n",
    "primary_structures = pad_sequence(seq_tensors, batch_first=True, padding_value=aa_pad_idx)\n",
    "\n",
    "# GET SECONDARY STRUCTURES\n",
    "ss_pad_idx = 3  # padding idx for DSSP if needed\n",
    "ss_tensors = [torch.tensor([dssp_to_idx.get(ss, ss_pad_idx) for ss in ss_seq]) for ss_seq in structures]\n",
    "secondary_structures = pad_sequence(ss_tensors, batch_first=True, padding_value=ss_pad_idx)\n",
    "\n",
    "print(primary_structures.shape)  # (num_sequences, max_seq_length)\n",
    "print(secondary_structures.shape)  # (num_sequences, max_seq_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50f8ce-50eb-4950-93d8-6ea4adcc2c14",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc32a6d-3bae-433a-94d6-68a99ef5bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, ss_vocab_size, d_model=128, n_heads=4, num_layers=2, dim_feedforward=256, dropout=0.1, aa_pad_idx=21, ss_pad_idx=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.aa_pad_idx = aa_pad_idx\n",
    "        self.ss_pad_idx = ss_pad_idx\n",
    "        \n",
    "        # Embeddings with padding_idx to zero-out padding embeddings\n",
    "        self.aa_embed = nn.Embedding(vocab_size, d_model, padding_idx=aa_pad_idx)\n",
    "        self.ss_embed = nn.Embedding(ss_vocab_size, d_model, padding_idx=ss_pad_idx)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_embed = nn.Embedding(700, d_model)  # max seq length\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, aa_ids, ss_ids):\n",
    "        \"\"\"\n",
    "        aa_ids: (batch, seq_len)\n",
    "        ss_ids: (batch, seq_len)\n",
    "        \"\"\"\n",
    "        bsz, seq_len = aa_ids.size()\n",
    "        \n",
    "        # Create padding mask: True where padding tokens are present\n",
    "        # Shape: (batch, seq_len)\n",
    "        padding_mask = (aa_ids == self.aa_pad_idx)\n",
    "        \n",
    "        # Embeddings\n",
    "        x = self.aa_embed(aa_ids) + self.ss_embed(ss_ids)\n",
    "        \n",
    "        # Positional encoding\n",
    "        positions = torch.arange(seq_len, device=aa_ids.device).unsqueeze(0).expand(bsz, seq_len)\n",
    "        x = x + self.pos_embed(positions)\n",
    "        \n",
    "        # Transformer expects src_key_padding_mask with True for padded positions\n",
    "        x = self.transformer(x, src_key_padding_mask=padding_mask)\n",
    "        \n",
    "        logits = self.fc_out(x)  # (batch, seq_len, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f34eb7-a8c3-449f-a9ed-765b3f5d12c0",
   "metadata": {},
   "source": [
    "## Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957236a7-b9d5-4d40-bfda-4bb09eb2fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: torch.Size([4292, 696])\n",
      "Validation set: torch.Size([1073, 696])\n"
     ]
    }
   ],
   "source": [
    "# datasets and dataloaders\n",
    "frac = 0.2 # fraction of points in valid set\n",
    "train_ps = primary_structures[int(np.shape(primary_structures)[0] * frac):,:]\n",
    "valid_ps = primary_structures[:int(np.shape(primary_structures)[0] * frac),:]\n",
    "train_ss = secondary_structures[int(np.shape(secondary_structures)[0] * frac):,:]\n",
    "valid_ss = secondary_structures[:int(np.shape(secondary_structures)[0] * frac),:]\n",
    "\n",
    "\n",
    "print('Training set:',np.shape(train_ps))\n",
    "print('Validation set:',np.shape(valid_ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aadb35d-1e04-4825-982e-381e2363f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1605212/54756858.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = ProteinDataset(torch.tensor(train_ps), torch.tensor(train_ss))\n",
      "/tmp/ipykernel_1605212/54756858.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_dataset = ProteinDataset(torch.tensor(valid_ps), torch.tensor(valid_ss))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, ps_tensor, ss_tensor):\n",
    "        assert ps_tensor.shape == ss_tensor.shape, \"ps and ss must have the same shape\"\n",
    "        self.ps = ps_tensor\n",
    "        self.ss = ss_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.ps.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ps[idx], self.ss[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ProteinDataset(torch.tensor(train_ps), torch.tensor(train_ss))\n",
    "valid_dataset = ProteinDataset(torch.tensor(valid_ps), torch.tensor(valid_ss))\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c224f6b-1ae5-4f28-a309-ce4e016f56ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1b55bd83f042b0b2abc531c670f7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training \n",
    "model = ProteinTransformer(vocab_size=22, ss_vocab_size=4, aa_pad_idx=21, ss_pad_idx=3)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=21)  # ignore padding in target loss\n",
    "num_epochs = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for aa_ids, ss_ids in loop:\n",
    "        aa_ids = aa_ids.to(device)\n",
    "        ss_ids = ss_ids.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_aa = aa_ids[:, :-1]\n",
    "        input_ss = ss_ids[:, :-1]\n",
    "        target_aa = aa_ids[:, 1:]\n",
    "\n",
    "        logits = model(input_aa, input_ss)\n",
    "\n",
    "        logits = logits.reshape(-1, logits.size(-1))\n",
    "        target_aa = target_aa.reshape(-1)\n",
    "\n",
    "        loss = criterion(logits, target_aa)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=running_loss / (loop.n + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79178f1-a2e3-4e8e-bc89-124acd989872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ProteinTransformer'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.9517\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for aa_ids, ss_ids in valid_loader:\n",
    "        aa_ids = aa_ids.to(device)\n",
    "        ss_ids = ss_ids.to(device)\n",
    "\n",
    "        input_aa = aa_ids[:, :-1]\n",
    "        input_ss = ss_ids[:, :-1]\n",
    "        target_aa = aa_ids[:, 1:]\n",
    "\n",
    "        logits = model(input_aa, input_ss)\n",
    "        logits = logits.reshape(-1, logits.size(-1))\n",
    "        target_aa = target_aa.reshape(-1)\n",
    "\n",
    "        loss = criterion(logits, target_aa)\n",
    "        total_loss += loss.item() * aa_ids.size(0)  # weighted sum\n",
    "val_loss = total_loss / len(valid_loader.dataset)\n",
    "perplexity = torch.exp(torch.tensor(val_loss))\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb657a-3c04-40c8-9018-04a881fe2387",
   "metadata": {},
   "source": [
    "# Evaluate on MMACHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365673a0-c3a2-47c3-9e77-a07036aa1829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q9Y4U1 → (700, 25)\n"
     ]
    }
   ],
   "source": [
    "# produce the sequence\n",
    "code = 'Q9Y4U1'\n",
    "faa = f\"fasta/{code}.fasta\"\n",
    "pdb_file = f\"pdb/{code}.pdb\"\n",
    "sec_map = ['H', 'E', 'C']\n",
    "max_len = 700\n",
    "try:\n",
    "    # --- 1. Load primary sequence ---\n",
    "    record = SeqIO.read(faa, \"fasta\")\n",
    "    seq = str(record.seq)\n",
    "    L = len(seq)\n",
    "\n",
    "    # --- 2. One-hot encode primary structure ---\n",
    "    prot = np.zeros((max_len, len(all_residues)), dtype=float)\n",
    "    for j, aa in enumerate(seq[:max_len]):  # truncate to 700\n",
    "        idx = all_residues.index(aa) if aa in all_residues else no_seq_idx\n",
    "        prot[j, idx] = 1\n",
    "\n",
    "    # --- 3. Parse secondary structure with DSSP ---\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(code, pdb_file)\n",
    "    model_DSSP = next(structure.get_models())\n",
    "\n",
    "    dssp = DSSP(model_DSSP, pdb_file)  # Requires DSSP installed\n",
    "    ss_list = []\n",
    "    for key in dssp.keys():\n",
    "        ss = dssp[key][2]  # DSSP secondary structure code\n",
    "        ss_list.append(ss if ss != ' ' else 'C')  # convert blanks to coil\n",
    "\n",
    "    # --- 4. One-hot encode secondary structure ---\n",
    "    sec = np.zeros((max_len, len(sec_map)), dtype=float)\n",
    "    for j, ss in enumerate(ss_list[:max_len]):  # truncate to 700\n",
    "        idx = sec_map.index(ss) if ss in sec_map else sec_map.index('C')\n",
    "        sec[j, idx] = 1\n",
    "\n",
    "    # --- 5. Combine features: primary (22) + secondary (3) ---\n",
    "    feat = np.concatenate([prot, sec], axis=1)  # shape: (700, 25)\n",
    "\n",
    "    print(f\"{code} → {feat.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Skipping {code} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f777c2f0-a2ab-426b-95c2-ecafaa791fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_test = np.argmax(prot, axis = 1)[:282]\n",
    "ss_test = np.argmax(sec, axis = 1)[:282]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11a40d75-b9eb-4a42-ae91-ef4f180f851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.9535\n",
      "Accuracy: 0.0355\n"
     ]
    }
   ],
   "source": [
    "# Encode secondary structure for your sequence (length must match primary)\n",
    "ss_seq = torch.tensor(ss_test, device=device)  # shape (1, seq_len)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    seq_idx = torch.tensor(ps_test, device=device)  # shape (1, seq_len)\n",
    "    \n",
    "    input_aa = seq_idx[:-1]\n",
    "    input_ss = ss_seq[:-1]\n",
    "    target_aa = seq_idx[:]\n",
    "    input_aa = torch.tensor(ps_test).unsqueeze(0)  # Shape: (1, seq_len)\n",
    "    input_ss = torch.tensor(ss_test).unsqueeze(0)  # Shape: (1, seq_len)\n",
    "    \n",
    "    \n",
    "    logits = model(input_aa, input_ss)\n",
    "    \n",
    "    logits = logits.reshape(-1, logits.size(-1))\n",
    "    target_aa = target_aa.reshape(-1)\n",
    "    \n",
    "    #loss = criterion(logits, target_aa)\n",
    "    print(f\"Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    predicted = torch.argmax(probs, dim=-1)\n",
    "    \n",
    "    accuracy = (predicted == target_aa).float().mean().item()\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "949f618c-755f-4110-9255-c81a33200de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 9, 0, 9, 9, 9, 0, 9, 9])\n",
      "tensor([ 9,  2, 13,  8, 18,  0,  2, 10,  8, 12])\n"
     ]
    }
   ],
   "source": [
    "print(predicted[:10])\n",
    "print(target_aa[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f80b3-231c-4114-adf7-c583b78c465a",
   "metadata": {},
   "source": [
    "# Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fdef00b-fb0b-4c0f-bc5c-6a1605701165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30588c85d6974ceeac3e6d009bfe0382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676adcbe2393446d81cf61bb0e7d7e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/361 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f078de9da3e4a529f2c66835333a39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf30c9060d914c5eafdc9fd0f9bd6a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0822fa3e55034c55818fa22eb4c063e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4a86077672451a89a388d24842f42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c926d64-bcc0-43ca-98bf-cc205a8ab57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
